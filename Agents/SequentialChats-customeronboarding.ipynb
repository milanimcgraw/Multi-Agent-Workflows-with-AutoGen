{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8140b161",
   "metadata": {},
   "source": [
    "# Sequential Chats and Customer Onboarding with AutoGen\n",
    "\n",
    "This notebook simulates mirrors a real-world customer onboarding pipeline using **AutoGen’s `ConversableAgent` and `initiate_chats`**. Rather than using a single, monolithic conversation, the onboarding process is modularized into sequential, specialized tasks—each handled by a dedicated agent.\n",
    "\n",
    "## **Human-in-the-loop Interaction**\n",
    "\n",
    "This workflow also supports **human input mode**, allowing users to type live responses directly into the conversation. The conversation proceeds when the human provides input, or the loop ends if a termination condition (like typing “exit”) is met.\n",
    "\n",
    "- The **`customer_proxy_agent`** is configured with `human_input_mode=\"ALWAYS\"`, enabling manual input when interacting with other agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4d307",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b75995-4ee4-4ff0-9c44-3943caae37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [{\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"], \n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce6700-8a33-424f-aefe-8852fd1e6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f979f9",
   "metadata": {},
   "source": [
    "## Defining AutoGen Agents\n",
    "\n",
    "**Each agent is configured with:**\n",
    "- a unique name\n",
    "- a system message describing its behavior\n",
    "- `llm_config` as the language model backend\n",
    "- `human_input_mode` and optional termination logic using `lambda` conditions\n",
    "---\n",
    "and tailored for a specific sub-task:\n",
    "- **`onboarding_personal_information_agent`**: Gathers the customer's name and location.\n",
    "- **`onboarding_topic_preference_agent`**: Asks about the customer’s topic preferences.\n",
    "- **`customer_engagement_agent`**: Provides relevant and engaging information based on prior responses.\n",
    "- **`customer_proxy_agent`**: Represents the customer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a527bb1e-dd4e-47b0-a1b7-a9cbcd87cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"onboarding_personal_information_agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bc9a24-a680-444d-943b-b740bce0189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"onboarding_topic_preference_agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6755a7fc-cb17-4d62-a03f-48e260f39010",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"customer_engagement_agent\",\n",
    "    system_message='''You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64267c0b-f7f2-46e6-ab44-6f7b5fbd9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f240408",
   "metadata": {},
   "source": [
    "## Creating Tasks\n",
    "\n",
    "The tasks are structured using a list of dictionaries:\n",
    "\n",
    "```python\n",
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\": \"Return the customer information into a JSON object only: {'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\": True,\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "- Each chat specifies the initiator, recipient, and prompt.\n",
    "- `summary_method` defines how the result is saved for downstream use.\n",
    "- `max_turns` limits the number of exchanges.\n",
    "- `clear_history` controls memory between tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b15af1d-7042-4569-a936-7966be203f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you get started with our product.\"\n",
    "            \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into as JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what topics you are \"\n",
    "                \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a066b",
   "metadata": {},
   "source": [
    "## Start the onboarding process\n",
    "This triggers the full sequence of tasks. Conversations run in the specified order and summaries from each chat are implicitly passed along. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d6d1d4a-0b50-41a5-a1f0-3ff208398bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33monboarding_personal_information_agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/autogen/agentchat/chat.py:57: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to onboarding_personal_information_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  Mia USA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to onboarding_personal_information_agent):\n",
      "\n",
      "Mia USA\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33monboarding_personal_information_agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you, Mia from the USA! Your onboarding is complete. If you need any further assistance, feel free to reach out. TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to onboarding_personal_information_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (7dbd6e13-67ca-489a-ba12-e6e4c8701e5a): Termination message condition on agent 'customer_proxy_agent' met\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (b574895d-e4c9-44d5-bed8-f1a4ee873026): Maximum turns (2) reached\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33monboarding_topic_preference_agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "```json\n",
      "{\n",
      "  \"name\": \"Mia\",\n",
      "  \"location\": \"USA\"\n",
      "}\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to onboarding_topic_preference_agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  philosophy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to onboarding_topic_preference_agent):\n",
      "\n",
      "philosophy\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (b430e416-c206-4b8d-b31a-f38b068dcdd5): Maximum turns (1) reached\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to customer_engagement_agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "```json\n",
      "{\n",
      "  \"name\": \"Mia\",\n",
      "  \"location\": \"USA\"\n",
      "}\n",
      "```\n",
      "Mia, from the USA, is interested in reading about philosophy.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_engagement_agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello Mia! Philosophical musings can be quite the mental workout, but I promise this will be a fun little journey. Did you know that ancient Greek philosophers could get pretty quirky? Let me share with you a fun fact about Diogenes of Sinope, one of the more eccentric philosophers from ancient Greece.\n",
      "\n",
      "Diogenes was known to live in a large ceramic jar instead of a conventional house. He often went around Athens in broad daylight with a lantern, claiming to be searching for an honest man but never finding one. His actions were meant to challenge the social values and notions of what constituted a civilized life during his time. \n",
      "\n",
      "Here's a little joke inspired by him: \n",
      "\n",
      "Why did Diogenes carry a lantern in daylight?\n",
      "\n",
      "Because he'd finally found the Ancient Greek version of \"Where’s Waldo!\"\n",
      "\n",
      "Philosophy has its serious sides, but sometimes the stories are as comedic as they are enlightening. Let me know if you'd love more fun stories about philosophical thinkers or any other intriguing tales! \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (554a6594-de2a-4058-808a-ebd890520551): Maximum turns (1) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e2713",
   "metadata": {},
   "source": [
    "## Chat Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e122f8a-1ceb-4635-9672-662114b0552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Mia\",\n",
      "  \"location\": \"USA\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "Mia, from the USA, is interested in reading about philosophy.\n",
      "\n",
      "\n",
      "Mia, who resides in the USA, is interested in fun philosophical content, particularly about ancient philosophers like Diogenes of Sinope, known for his eccentric behavior and humorous tales that challenge social values.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674c4eb",
   "metadata": {},
   "source": [
    "## Cost\n",
    "\n",
    "Token-level and cost breakdown per interaction are provided, which can be useful for tracking API expenses and optimizing prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b82a10a-afe5-4ba3-97b4-41c8c14b739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.0010250000000000003, 'gpt-4o-2024-08-06': {'cost': 0.0010250000000000003, 'prompt_tokens': 214, 'completion_tokens': 49, 'total_tokens': 263}}, 'usage_excluding_cached_inference': {'total_cost': 0.0010250000000000003, 'gpt-4o-2024-08-06': {'cost': 0.0010250000000000003, 'prompt_tokens': 214, 'completion_tokens': 49, 'total_tokens': 263}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.00034750000000000004, 'gpt-4o-2024-08-06': {'cost': 0.00034750000000000004, 'prompt_tokens': 83, 'completion_tokens': 14, 'total_tokens': 97}}, 'usage_excluding_cached_inference': {'total_cost': 0.00034750000000000004, 'gpt-4o-2024-08-06': {'cost': 0.00034750000000000004, 'prompt_tokens': 83, 'completion_tokens': 14, 'total_tokens': 97}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.0034974999999999997, 'gpt-4o-2024-08-06': {'cost': 0.0034974999999999997, 'prompt_tokens': 415, 'completion_tokens': 246, 'total_tokens': 661}}, 'usage_excluding_cached_inference': {'total_cost': 0.0034974999999999997, 'gpt-4o-2024-08-06': {'cost': 0.0034974999999999997, 'prompt_tokens': 415, 'completion_tokens': 246, 'total_tokens': 661}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
